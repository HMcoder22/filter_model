{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b628a7-0ee5-4dd5-aaa6-9c0d3ff582fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import json\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "uri = \"mongodb+srv://seymur:seymur23@hagosmarketing.8mru08u.mongodb.net/?retryWrites=true&w=majority&appName=HagosMarketing\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "\n",
    "# Cleaning data for persona\n",
    "\n",
    "db = client['Big5_US_Data']\n",
    "\n",
    "collection = db['Big5']\n",
    "\n",
    "documents = collection.find({})\n",
    "\n",
    "# Convert the documents to a list\n",
    "documents_list = list(documents)\n",
    "\n",
    "# Convert the list of documents to a pandas DataFrame\n",
    "person_data = pd.DataFrame(documents_list)\n",
    "person_data.drop('_id', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "features_without_null_values = []\n",
    "features_with_null_values = []\n",
    "\n",
    "null_fractions = person_data.isnull().mean()\n",
    "\n",
    "for i, null_fraction in null_fractions.items():\n",
    "    null_percentage = null_fraction * 100\n",
    "    if null_fraction == 1 or null_fraction > 0.2:\n",
    "        features_with_null_values.append(i)\n",
    "    else:\n",
    "        features_without_null_values.append(i)\n",
    "        \n",
    "        \n",
    "person_data.drop(features_with_null_values, axis = 1, inplace = True)\n",
    "person_data.dropna(inplace = True)\n",
    "\n",
    "bins = [0, 15, 19, 24, 34, 44, 54, 64, float('inf')]\n",
    "labels = ['age_0_15', 'age_16_19', 'age_20_24', 'age_25_34', 'age_35_44', 'age_45_54', 'age_55_64', 'age_65']\n",
    "\n",
    "person_data['age_group'] = pd.cut(person_data['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "# Cleaning data for persona \n",
    "\n",
    "db = client['US_Census_Data']\n",
    "\n",
    "collection = db['Median_Age_Occupation']\n",
    "\n",
    "documents = collection.find({})\n",
    "\n",
    "# Convert the documents to a list\n",
    "documents_list = list(documents)\n",
    "\n",
    "# Convert the list of documents to a pandas DataFrame\n",
    "accupation_for_age = pd.DataFrame(documents_list)\n",
    "accupation_for_age.drop('_id', axis = 1, inplace = True)\n",
    "\n",
    "features_without_null_values = []\n",
    "features_with_null_values = []\n",
    "\n",
    "null_fractions = accupation_for_age.isnull().mean()\n",
    "\n",
    "for i, null_fraction in null_fractions.items():\n",
    "    null_percentage = null_fraction * 100\n",
    "    if null_fraction == 1 or null_fraction > 0.2:\n",
    "        features_with_null_values.append(i)\n",
    "    else:\n",
    "        features_without_null_values.append(i)\n",
    "        \n",
    "accupation_for_age.drop(features_with_null_values, axis = 1, inplace = True)\n",
    "accupation_for_age.dropna(inplace = True)\n",
    "\n",
    "\n",
    "age_categories = [\n",
    "    \"age_16_19\",\n",
    "    \"age_20_24\",\n",
    "    \"age_25_34\",\n",
    "    \"age_35_44\",\n",
    "    \"age_45_54\",\n",
    "    \"age_55_64\",\n",
    "    \"age_65\",\n",
    "]\n",
    "\n",
    "# List to store the transformed data\n",
    "transformed_data = []\n",
    "\n",
    "# Transform the data\n",
    "for index, row in accupation_for_age.iterrows():\n",
    "    for i, age_category in enumerate(age_categories):\n",
    "        transformed_data.append({\n",
    "            \"occupation\": row['occupation'],\n",
    "            \"age_group\": age_category,\n",
    "            \"count_people\": row['median_age'][i],\n",
    "            \"median_age\": row['median_age'][-1]\n",
    "        })\n",
    "\n",
    "# Create the new DataFrame\n",
    "accupation_for_age2 = pd.DataFrame(transformed_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cleaning data for apply after filter\n",
    "\n",
    "\n",
    "\n",
    "# Cleaning of economy count level\n",
    "db = client['ACS_Nationwide']\n",
    "\n",
    "collection = db['Economics County Level']\n",
    "\n",
    "documents = collection.find({})\n",
    "\n",
    "# Convert the documents to a list\n",
    "documents_list = list(documents)\n",
    "\n",
    "info_about_state = pd.DataFrame(documents_list)\n",
    "info_about_state.drop('_id', axis = 1, inplace = True)\n",
    "\n",
    "features_without_null_values = []\n",
    "features_with_null_values = []\n",
    "\n",
    "null_fractions = info_about_state.isnull().mean()\n",
    "\n",
    "for i, null_fraction in null_fractions.items():\n",
    "    null_percentage = null_fraction * 100\n",
    "    if null_fraction == 1 or null_fraction > 0.2:\n",
    "        features_with_null_values.append(i)\n",
    "    else:\n",
    "        features_without_null_values.append(i)\n",
    "        \n",
    "\n",
    "info_about_state.drop(features_with_null_values, axis = 1, inplace = True)\n",
    "\n",
    "info_about_state.columns = info_about_state.iloc[0]  \n",
    "info_about_state = info_about_state[1:]  \n",
    "info_about_state = info_about_state.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Cleaning economics state\n",
    "\n",
    "db = client['ACS_Nationwide']\n",
    "\n",
    "collection = db['Economics State']\n",
    "\n",
    "documents = collection.find({})\n",
    "\n",
    "# Convert the documents to a list\n",
    "documents_list = list(documents)\n",
    "\n",
    "# Convert the list of documents to a pandas DataFrame\n",
    "economic_about_state = pd.DataFrame(documents_list)\n",
    "economic_about_state.drop('_id', axis = 1, inplace = True)\n",
    "df_melted = pd.melt(economic_about_state, id_vars=['Label (Grouping)'], var_name='State_Column', value_name='Value')\n",
    "# Pivot the DataFrame\n",
    "economic_about_state_pivot = df_melted.pivot_table(index='State_Column', columns='Label (Grouping)', values='Value', aggfunc='first')\n",
    "# Reset the index to turn 'State_Column' into a column\n",
    "economic_about_state_pivot.reset_index(inplace=True)\n",
    "\n",
    "features_without_null_values = []\n",
    "features_with_null_values = []\n",
    "\n",
    "null_fractions = economic_about_state_pivot.isnull().mean()\n",
    "\n",
    "for i, null_fraction in null_fractions.items():\n",
    "    null_percentage = null_fraction * 100\n",
    "    if null_fraction == 1 or null_fraction > 0.2:\n",
    "        features_with_null_values.append(i)\n",
    "    else:\n",
    "        features_without_null_values.append(i)\n",
    "        \n",
    "        \n",
    "economic_about_state_pivot.drop(features_with_null_values, axis = 1, inplace = True) \n",
    "\n",
    "economic_about_state_pivot = economic_about_state_pivot[economic_about_state_pivot['State_Column'].str.contains('Estimate')]\n",
    "# Extract state names\n",
    "economic_about_state_pivot['State_Name'] = economic_about_state_pivot['State_Column'].str.split('!!').str[0]\n",
    "economic_about_state_pivot.drop('State_Column', axis = 1, inplace = True)\n",
    "\n",
    "economic_about_state_pivot.rename(columns = {'State_Name':'state'}, inplace = True)\n",
    "\n",
    "economic_about_state_pivot['state'] = economic_about_state_pivot['state'].apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "# Cleaning social\n",
    "\n",
    "db = client['ACS_Nationwide']\n",
    "\n",
    "collection = db['Social Characteristics']\n",
    "\n",
    "documents = collection.find({})\n",
    "\n",
    "# Convert the documents to a list\n",
    "documents_list = list(documents)\n",
    "\n",
    "# Convert the list of documents to a pandas DataFrame\n",
    "social_char = pd.DataFrame(documents_list)\n",
    "social_char.drop('_id', axis = 1, inplace = True)\n",
    "\n",
    "df_melted = pd.melt(social_char, id_vars=['Label (Grouping)'], var_name='State_Column', value_name='Value')\n",
    "\n",
    "# Pivot the DataFrame\n",
    "social_char_pivot = df_melted.pivot_table(index='State_Column', columns='Label (Grouping)', values='Value', aggfunc='first')\n",
    "\n",
    "# Reset the index to turn 'State_Column' into a column\n",
    "social_char_pivot.reset_index(inplace=True)\n",
    "\n",
    "features_without_null_values = []\n",
    "features_with_null_values = []\n",
    "\n",
    "null_fractions = social_char_pivot.isnull().mean()\n",
    "\n",
    "for i, null_fraction in null_fractions.items():\n",
    "    null_percentage = null_fraction * 100\n",
    "    if null_fraction == 1 or null_fraction > 0.2:\n",
    "        features_with_null_values.append(i)\n",
    "    else:\n",
    "        features_without_null_values.append(i)\n",
    "        \n",
    "        \n",
    "social_char_pivot.drop(features_with_null_values, axis = 1, inplace = True)\n",
    "social_char_pivot = social_char_pivot[social_char_pivot['State_Column'].str.contains('Estimate')]\n",
    "# Extract state names\n",
    "social_char_pivot['State_Name'] = social_char_pivot['State_Column'].str.split('!!').str[0]\n",
    "\n",
    "social_char_pivot.rename(columns = {'State_Name':'state'}, inplace = True)\n",
    "social_char_pivot['state'] = social_char_pivot['state'].apply(lambda x: x.lower())\n",
    "social_char_pivot.drop('State_Column', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Cleaning demographic\n",
    "\n",
    "db = client['ACS_Nationwide']\n",
    "\n",
    "collection = db['demographic characteristics - US & State level']\n",
    "\n",
    "documents = collection.find({})\n",
    "\n",
    "# Convert the documents to a list\n",
    "documents_list = list(documents)\n",
    "\n",
    "# Convert the list of documents to a pandas DataFrame\n",
    "demographic_df = pd.DataFrame(documents_list)\n",
    "demographic_df.drop('_id', axis = 1, inplace = True)\n",
    "\n",
    "df_melted = pd.melt(demographic_df, id_vars=['Label (Grouping)'], var_name='State_Column', value_name='Value')\n",
    "# Pivot the DataFrame\n",
    "demographic_pivot = df_melted.pivot_table(index='State_Column', columns='Label (Grouping)', values='Value', aggfunc='first')\n",
    "# Reset the index to turn 'State_Column' into a column\n",
    "demographic_pivot.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "features_without_null_values = []\n",
    "features_with_null_values = []\n",
    "\n",
    "null_fractions = demographic_pivot.isnull().mean()\n",
    "\n",
    "for i, null_fraction in null_fractions.items():\n",
    "    null_percentage = null_fraction * 100\n",
    "    if null_fraction == 1 or null_fraction > 0.2:\n",
    "        features_with_null_values.append(i)\n",
    "    else:\n",
    "        features_without_null_values.append(i)\n",
    "        \n",
    "demographic_pivot.drop(features_with_null_values, axis = 1, inplace = True)       \n",
    "\n",
    "demographic_pivot = demographic_pivot[demographic_pivot['State_Column'].str.contains('Estimate')]\n",
    "# Extract state names\n",
    "demographic_pivot['State_Name'] = demographic_pivot['State_Column'].str.split('!!').str[0]\n",
    "demographic_pivot.drop('State_Column', axis = 1, inplace = True)\n",
    "\n",
    "demographic_pivot.rename(columns = {'State_Name':'state'}, inplace = True)\n",
    "demographic_pivot['state'] = demographic_pivot['state'].apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "# Cleaning information\n",
    "\n",
    "db = client['Persona']\n",
    "\n",
    "collection = db['Information']\n",
    "\n",
    "documents = collection.find({})\n",
    "\n",
    "# Convert the documents to a list\n",
    "documents_list = list(documents)\n",
    "\n",
    "# Convert the list of documents to a pandas DataFrame\n",
    "accupa_wage = pd.DataFrame(documents_list)\n",
    "accupa_wage.drop('_id', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "features_without_null_values = []\n",
    "features_with_null_values = []\n",
    "\n",
    "null_fractions = accupa_wage.isnull().mean()\n",
    "\n",
    "for i, null_fraction in null_fractions.items():\n",
    "    null_percentage = null_fraction * 100\n",
    "    if null_fraction == 1 or null_fraction > 0.2:\n",
    "        features_with_null_values.append(i)\n",
    "    else:\n",
    "        features_without_null_values.append(i)\n",
    "    \n",
    "    \n",
    "    \n",
    "accupa_wage.drop(features_with_null_values, axis = 1, inplace = True)\n",
    "accupation_data = []\n",
    "\n",
    "for index, row in accupa_wage.iterrows():\n",
    "    occupation_dict = row['occupation']\n",
    "    if 'job' in occupation_dict and 'employment' in occupation_dict:\n",
    "        accupation_data.append({\n",
    "            'state': row['state'],\n",
    "            'occupation': occupation_dict['job'],\n",
    "            'employment': occupation_dict['employment'],\n",
    "            'income': occupation_dict['income']\n",
    "        })\n",
    "accupa_wage_df = pd.DataFrame(accupation_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The prediction part\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    input_features = request.get_json()\n",
    "    \n",
    "    input_df = pd.DataFrame([input_features])\n",
    "\n",
    "    # Filter and transform data based on input features\n",
    "    filter_df_persona = person_data[(person_data[['gender', 'country', 'state']] == input_df[['gender', 'country', 'state']].values[0]).all(axis=1)]\n",
    "    filter_df_accupation = accupation_for_age2[accupation_for_age2['occupation'] == input_df['occupation'].loc[0]]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled_persona = pd.DataFrame(scaler.fit_transform(filter_df_persona[['age']]), index=filter_df_persona.index)\n",
    "    input_scaled = pd.DataFrame(scaler.transform(input_df[['age']]), index=input_df.index)\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "    knn.fit(df_scaled_persona)\n",
    "\n",
    "    distances, indices = knn.kneighbors(input_scaled)\n",
    "    top_10_similar_persons_knn = df_scaled_persona.iloc[indices.flatten()]\n",
    "    indexes = top_10_similar_persons_knn.index.to_list()\n",
    "\n",
    "    result_df_persona = filter_df_persona[filter_df_persona.index.isin(indexes)]\n",
    "\n",
    "    search_df = pd.merge(result_df_persona, filter_df_accupation, on='age_group', how='left')\n",
    "    search_df2 = pd.merge(search_df, accupa_wage_df, on = ['state','occupation'], how = 'left')\n",
    "    search_df3 = pd.merge(search_df2, demographic_pivot, on = 'state', how = 'left')\n",
    "    search_df4 = pd.merge(search_df3, social_char_pivot, on = 'state', how = 'left')\n",
    "    search_df5 = pd.merge(search_df4, economic_about_state_pivot, on = 'state', how = 'left')\n",
    "\n",
    "    features_without_null_values = []\n",
    "    features_with_null_values = []\n",
    "    \n",
    "    null_fractions = search_df5.isnull().mean()\n",
    "    \n",
    "    for i, null_fraction in null_fractions.items():\n",
    "        null_percentage = null_fraction * 100\n",
    "        if null_fraction == 1 or null_fraction > 0.2:\n",
    "            features_with_null_values.append(i)\n",
    "        else:\n",
    "            features_without_null_values.append(i)\n",
    "            \n",
    "    search_df5.drop(features_with_null_values, axis = 1, inplace = True)\n",
    "    search_df5 = search_df5.loc[:, ~search_df5.isin(['(X)']).any()]\n",
    "\n",
    "    # Convert the final dataframe to JSON and return\n",
    "    return jsonify(search_df5.to_dict(orient='records'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71606459-8355-40d6-9489-80cdf1a7d3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156f874-7a77-4b47-9427-79454e1eb11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
